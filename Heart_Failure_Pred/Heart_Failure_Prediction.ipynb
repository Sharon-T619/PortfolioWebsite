{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary Analysis\n",
    "#1. Dataset information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Data description\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Find Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Check for duplicated entries\n",
    "df.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Segregating Columns into groups\n",
    "#Numerical -> Age, RestingBP, Cholesterol, MaxHR, OldPeak, HeartDisease, FastingBS\n",
    "#Categorical -> Sex, ChestPainType, RestingECG, ExerciseAngina, ST_Slope\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Analysis on Age\n",
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "ax[0] = sns.histplot(data=df, x='Age', linewidth=1, edgecolor='black', ax=ax[0], color='#f7d794')\n",
    "ax[0].set(title='Age Distribution - Histogram')\n",
    "\n",
    "ax[1] = sns.kdeplot(data=df, x='Age', fill=True, edgecolor='black', ax=ax[1], color='#e15f41')\n",
    "ax[1] = sns.rugplot(data=df, x='Age', ax=ax[1], color='#574b90')\n",
    "ax[1].set(title='Age Distribution - KDE Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Skewness\n",
    "df['Age'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking For Outliers\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "sns.boxplot(data=df, x='Age', color='#7ed6df')\n",
    "sns.stripplot(data=df, x='Age', linewidth = 0.6, size=3, color='#be2edd')\n",
    "plt.title('Age Distribution',fontsize= 14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Conclusions:\n",
    "#1.No missing values\n",
    "#2.Data is almost normal\n",
    "#3.No outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Analysis on RestingBP\n",
    "df['RestingBP'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "ax[0] = sns.histplot(data=df, x='RestingBP', linewidth=1, edgecolor='black', ax=ax[0], color='#D980FA')\n",
    "ax[0].set(title='Resting Blood Pressure Distribution - Histogram')\n",
    "\n",
    "ax[1] = sns.kdeplot(data=df, x='RestingBP', fill=True, edgecolor='black', ax=ax[1], color='#9980FA')\n",
    "ax[1] = sns.rugplot(data=df, x='RestingBP', ax=ax[1], color='#574b90')\n",
    "ax[1].set(title='Resting Blood Pressure Distribution - KDE Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RestingBP Skewness\n",
    "df['RestingBP'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking For Outliers\n",
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "sns.boxplot(data=df, x='RestingBP', color='#ED4C67')\n",
    "sns.stripplot(data=df, x='RestingBP', linewidth = 0.6, size=3, color='#833471')\n",
    "plt.title('Resting Blood Pressure Distribution',fontsize= 14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Conclusions:\n",
    "#1.No missing values\n",
    "#2.Almost normal distribution\n",
    "#3.There are some outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Analysis on Cholesterol\n",
    "df['Cholesterol'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "ax[0] = sns.histplot(data=df, x='Cholesterol', linewidth=1, edgecolor='black', ax=ax[0], color='#EA2027')\n",
    "ax[0].set(title='Cholesterol Distribution - Histogram')\n",
    "\n",
    "ax[1] = sns.kdeplot(data=df, x='Cholesterol', fill=True, edgecolor='black', ax=ax[1], color='#F79F1F')\n",
    "ax[1] = sns.rugplot(data=df, x='Cholesterol', ax=ax[1], color='#FFC312')\n",
    "ax[1].set(title='Cholesterol Distribution - KDE Plot')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cholesterol skewness\n",
    "df['Cholesterol'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking For Outliers\n",
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "sns.boxplot(data=df, x='Cholesterol', color='#C4E538')\n",
    "sns.stripplot(data=df, x='Cholesterol', linewidth = 0.6, size=3, color='#009432')\n",
    "plt.title('Cholestrol Distribution',fontsize= 14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploring the outliers\n",
    "df[(df['Cholesterol'] == 0) & df['HeartDisease'] == 1]\n",
    "df[(df['Cholesterol'] > 450)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Conclusions:\n",
    "#No missing values\n",
    "#This follows a Bimodal distribution\n",
    "#Often, high cholesterol is related to risk of heart disease. But in our data, we can see that even people having 0 cholesterol (with other normal parameters) are prone to heart disease _ could be an error in entering values\n",
    "#On the other side of the spectrum, values above 400, are high but they are not outliers cause the range goes as high as 800. And these people also have a risk of heart disease with high cholesterol. So, this seems kind of legit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Analysis on Max Heart Rate\n",
    "df['MaxHR'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "ax[0] = sns.histplot(data=df, x='MaxHR', linewidth=1, edgecolor='black', ax=ax[0], color='#00a8ff')\n",
    "ax[0].set(title='max Heart Rate Distribution - Histogram')\n",
    "\n",
    "ax[1] = sns.kdeplot(data=df, x='MaxHR', fill=True, edgecolor='black', ax=ax[1], color='#9c88ff')\n",
    "# ax[1] = sns.rugplot(data=df, x='MaxHR', ax=ax[1], color='#487eb0')\n",
    "ax[1].set(title='max Heart Rate Distribution - KDE Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxHR Skewness\n",
    "df['MaxHR'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking For Outliers\n",
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "sns.boxplot(data=df, x='MaxHR', color='#52b69a')\n",
    "sns.stripplot(data=df, x='MaxHR', linewidth = 0.6, size=3, color='#d9ed92')\n",
    "plt.title('Max Heart Rate Distribution',fontsize= 14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the outliers\n",
    "df.query(\"MaxHR < 70\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Conclusions:\n",
    "#1.No null values\n",
    "#2.Almost normally distributed\n",
    "#3.There are handful outliers\n",
    "#4.Most people have a max heart rate of 150, which seems okay as most of the people in this dataset are aged between 50 - 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Univariate Analysis on Categorical \n",
    "\n",
    "## Analysis on Heart Disease\n",
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "ax = sns.barplot(data=df['HeartDisease'].value_counts().reset_index(), x='index', y='HeartDisease', \n",
    "           linewidth=1, edgecolor='black', palette='Set3', ax=ax)\n",
    "ax.set(title='Count of Heart Disease Vs No Heart Disease', ylabel='Count', xlabel='Heart Disease')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Conclusions:\n",
    "# A higher number of patients in the dataset have risk of suffering from a heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis on Sex\n",
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "ax = sns.barplot(data=df['Sex'].value_counts().reset_index(), x='index', y='Sex', \n",
    "           linewidth=1, edgecolor='black', palette='Set2', ax=ax)\n",
    "ax.set(title='Count of Male Vs Female', ylabel='Count', xlabel='Sex')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Conclusions:\n",
    "# The dataset predominantly consists of records from males, outnumbering female records.\n",
    "# The male records significantly outnumber the female records in this dataset, with a ratio of more than three to one.\n",
    "# It is important to be mindful of this gender imbalance in our dataset to avoid introducing bias when making assumptions or drawing conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis on Chest Pain Type\n",
    "\n",
    "### ASY : ASY = \"Asymptomatic\" chest pain. It indicates that the individuals in the dataset did not experience any noticeable chest pain symptoms. \n",
    "#They may have been included in the dataset for other reasons, such as a medical examination or routine check-up.\n",
    "\n",
    "### NAP : NAP = \"Non-Anginal Pain\" chest pain. Non-anginal pain refers to chest discomfort or pain that is not related to a reduced blood supply to the heart. \n",
    "#It is typically not caused by underlying heart disease but may still be a cause of concern and require further evaluation.\n",
    "\n",
    "### ATA : ATA = \"Atypical Angina\" chest pain. Atypical angina refers to chest pain that does not fit the typical pattern of symptoms associated with angina. \n",
    "#It may have different characteristics or be triggered by factors other than physical exertion or emotional stress.\n",
    "\n",
    "### TA : TA stands for \"Typical Angina\" chest pain. Typical angina refers to chest pain that follows a predictable pattern and is commonly associated with coronary artery disease. \n",
    "#It is typically described as a squeezing or pressure-like sensation in the chest that is brought on by physical exertion or emotional stress and is relieved with rest or nitroglycerin medication.\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "ax = sns.barplot(data=df['ChestPainType'].value_counts().reset_index(), x='index', y='ChestPainType', \n",
    "           linewidth=1, edgecolor='black', palette='Set1', ax=ax)\n",
    "ax.set(title='Count of Chest Pain Types', ylabel='Count', xlabel='Chest Pain Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Conclusions:\n",
    "#The majority of individuals in the dataset did not report any noticeable symptoms of chest pain, this suggests that noticeable chest pain may not be the primary symptom associated with heart disease.\n",
    "#Can be sure of this when we do the bivarite analysis of Chest Pain Type and the Heart Disease Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BIVARIATE ANALYSIS\n",
    "\n",
    "#Bivariate analysis is the examination of the relationship between two variables. Here are three key points about bivariate analysis:\n",
    "\n",
    "#1. Relationship Exploration: Bivariate analysis helps uncover patterns, associations, or connections between two variables. \n",
    "#It allows us to understand how changes in one variable correspond to changes in another variable.\n",
    "\n",
    "#2. Correlation Assessment: Bivariate analysis helps us assess the strength and direction of the relationship between two variables. \n",
    "#It enables us to determine if the variables are positively, negatively, or not correlated at all.\n",
    "\n",
    "#3. Visual Representation: Bivariate analysis often involves the use of visualizations such as scatter plots, line graphs, or heatmaps. \n",
    "#These visual representations provide a clear and concise way to understand the relationship between the two variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis between Heart Disease and Age:\n",
    "# Which age group is most prone to heart disease?\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.kdeplot(data = df[df['HeartDisease'] == 1], x='Age', fill=True,   color='#0683c9', label='No Heart Disease')\n",
    "sns.kdeplot(data = df[df['HeartDisease'] == 0], x='Age', fill=True,  color='#f5e840', label='Has Heart Disease')\n",
    "plt.legend()\n",
    "plt.title('Age and Heart Disease')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Conclusions:\n",
    "#1. Individuals under the age of 50 have a lower likelihood of experiencing heart disease.\n",
    "#2. Once individuals reach the age of 50, the risk of developing heart disease significantly increases.\n",
    "#3. The age group between 50 and 55 shows the highest susceptibility to heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis between Heart Disease and Gender:\n",
    "# Which gender is most prone to heart disease?\n",
    "temp_df = pd.crosstab(df['HeartDisease'], df['Sex'])\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "ax[0] = sns.heatmap(data=temp_df, annot=True, ax=ax[0],fmt='0g', linewidths=0.01, cmap='summer_r', linecolor='#95d5b2')\n",
    "ax[0].set(title='Heatmap of Gender Vs Heart Disease', ylabel='Heart Disease')\n",
    "\n",
    "ax[1] = sns.countplot(data=df, x=\"Sex\", hue=\"HeartDisease\", palette = 'Set2', ax=ax[1], edgecolor='black')\n",
    "ax[1].set(title='Countplot of Gender Vs Heart Disease', ylabel='Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Conclusions:\n",
    "#1. The occurrence of heart disease is more prevalent among males compared to females.\n",
    "#2. The dataset contains significantly more data for males than females, almost three times as much.\n",
    "#3. However, when considering the percentages, approximately 25% of females in the dataset have heart disease, while a higher percentage of around 63% of males have heart disease.\n",
    "# These observations highlight the gender disparity in the prevalence of heart disease, with a higher proportion of males being affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis between Heart Disease and Cholesterol:\n",
    "# Does Cholesterol play a role in heart disease?\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.kdeplot(data = df[df['HeartDisease'] == 1], x='Cholesterol', fill=True,   color='#b5e48c', label='No Heart Disease')\n",
    "sns.kdeplot(data = df[df['HeartDisease'] == 0], x='Cholesterol', fill=True,  color='#CC1011', label='Has Heart Disease')\n",
    "plt.legend()\n",
    "plt.title('Age and Heart Disease')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conclusions:\n",
    "#Cholesterol Ranges\n",
    "## Normal: less than 150 mg/dL.\n",
    "## Mild hypertriglyceridemia: 150 to 499 mg/dL.\n",
    "## Moderate hypertriglyceridemia: 500 to 886 mg/dL.\n",
    "## Very high or severe hypertriglyceridemia: greater than 886 mg/dL.\n",
    "\n",
    "\n",
    "# The analysis reveals that individuals with cholesterol levels below 150 mg/dL are generally considered healthy.\n",
    "# There are still a significant number of healthy individuals above this range, the number of individuals prone to heart disease is also substantially higher.\n",
    "# These findings suggest that higher cholesterol levels do indeed pose an increased risk of heart disease.\n",
    "## These observations support the notion that elevated cholesterol levels contribute to a higher likelihood of developing heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis between Heart Disease and Chest Pain Type:\n",
    "# What does Chest Pain Type tell us about Heart Disease?\n",
    "temp_df = pd.crosstab(df['HeartDisease'], df['ChestPainType'])\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "ax[0] = sns.heatmap(data=temp_df,annot=True,fmt='0g', ax = ax[0],linewidths=0.01, cmap='mako_r', linecolor='#cae9ff')\n",
    "ax[0].set(title='Heatmap of Chest Pain Type Vs Heart Disease', ylabel='Heart Disease')\n",
    "\n",
    "ax[1] = sns.countplot(data=df, x=\"ChestPainType\", hue=\"HeartDisease\", palette = 'Set2', ax=ax[1], edgecolor='black')\n",
    "ax[1].set(title='Countplot of Chest Pain Type Vs Heart Disease', ylabel='Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Conclusions:\n",
    "#1. A significant proportion of people who have heart disease do not experience any chest pain symptoms. This type of chest pain is called Asymptomatic Chest Pain.\n",
    "#2. The next largest group of people with heart disease experience Atypical Angina, which means they may have chest pain or discomfort that differs from the typical chest pain associated with heart disease.\n",
    "# These findings suggest that heart disease can manifest without the presence of chest pain. It implies that not all cases of heart disease are accompanied by chest pains, and individuals may have heart disease without experiencing typical chest pain symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis between Heart Disease and Exercise Angina:\n",
    "# Can exercise cause heart disease?\n",
    "\n",
    "# Exercise Angina, also known as exertional angina or angina pectoris, refers to chest pain or discomfort that occurs during physical activity or exercise. \n",
    "# It is a symptom typically associated with coronary artery disease, which is a condition where the arteries that supply blood to the heart become narrowed or blocked.\n",
    "\n",
    "temp_df = pd.crosstab(df['HeartDisease'], df['ExerciseAngina'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "ax[0] = sns.heatmap(data=temp_df,annot=True,fmt='0g', ax = ax[0],linewidths=0.01, cmap='mako_r', linecolor='#cae9ff')\n",
    "ax[0].set(title='Heatmap of Exercise Angina Vs Heart Disease', ylabel='Heart Disease')\n",
    "\n",
    "ax[1] = sns.countplot(data=df, x=\"ExerciseAngina\", hue=\"HeartDisease\", palette = 'Set2', ax=ax[1], edgecolor='black')\n",
    "ax[1].set(title='Countplot of Exercise Angina Vs Heart Disease', ylabel='Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis between Heart Disease and Fasting Blood Sugar:\n",
    "# How is Fasting Blood Sugar related to Heart Disease?\n",
    "\n",
    "# What is Fasting Blood Sugar? - Fasting blood sugar, also known as fasting blood glucose, refers to the level of glucose (sugar) in the bloodstream after an overnight fast. \n",
    "#It is typically measured in milligrams per deciliter (mg/dL) or millimoles per liter (mmol/L).\n",
    "#Fasting blood sugar is an important parameter used in diagnosing and monitoring diabetes.\n",
    "#It provides information about the body's ability to regulate blood glucose levels in the absence of food intake.\n",
    "#Normally, when a person has fasted for at least 8 hours, the fasting blood sugar level should fall within a specific range.\n",
    "\n",
    "##Note\n",
    "#In this dataset 0 means normal Fasting Blood Sugar level and 1 means Abnormal Blood Sugar level\n",
    "\n",
    "temp_df = pd.crosstab(df['HeartDisease'], df['FastingBS'])\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(figsize= (6,4))\n",
    "\n",
    "ax = sns.heatmap(data=temp_df,annot=True,fmt='0g', ax = ax,linewidths=0.01, cmap='summer_r', linecolor='#cae9ff')\n",
    "ax.set(title='Heatmap of Fasting Blood Sugar Vs Heart Disease', ylabel='Heart Disease', xlabel='Fasting Blood Sugar')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Conclusions:\n",
    "# Based on the heatmap analysis, it is evident that individuals with normal fasting blood sugar levels are also susceptible to heart disease. \n",
    "# In fact, they exhibit a higher likelihood of developing heart disease compared to those with abnormal fasting blood sugar levels.\n",
    "# This suggests that while fasting blood sugar levels can be a factor in the development or presence of heart disease, it is not the sole determining factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Data Preprocessing \n",
    "\n",
    "## Label encoding of categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "features = ['Sex','ChestPainType','RestingECG','ExerciseAngina', 'ST_Slope']\n",
    "le = LabelEncoder()\n",
    "for feature in features:\n",
    "    le.fit(df[feature].unique())\n",
    "    df[feature] = le.transform(df[feature])\n",
    "    print(feature, df[feature].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardization\n",
    "# Standardize the continuous variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[['Age', 'RestingBP', 'Cholesterol','MaxHR','Oldpeak']] = scaler.fit_transform(df[['Age', 'RestingBP', 'Cholesterol','MaxHR','Oldpeak']])\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate dataset into train_test dataset\n",
    "from sklearn import model_selection\n",
    "y = df['HeartDisease']\n",
    "X = df.drop('HeartDisease', axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training data has ' + str(X_train.shape[0]) + ' observation with ' + str(X_train.shape[1]) + ' features')\n",
    "print('test data has ' + str(X_test.shape[0]) + ' observation with ' + str(X_test.shape[1]) + ' features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Training & Evaluation\n",
    "## Build models\n",
    "# Models for the project\n",
    "from sklearn. ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# For confusion matrix\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "# Logistic Regression\n",
    "classifier_logistic = LogisticRegression()\n",
    "\n",
    "# K Nearest Neighbors\n",
    "classifier_KNN = KNeighborsClassifier()\n",
    "\n",
    "# Random Forest\n",
    "classifier_RF = RandomForestClassifier()\n",
    "\n",
    "# Support Vector Classification\n",
    "classifier_SVC = SVC(probability=True)\n",
    "\n",
    "# GB classifier\n",
    "classifier_GB = GradientBoostingClassifier()\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "classifier_NB = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regressional Classifier and evaluation\n",
    "classifier_logistic.fit(X_train, y_train) # Train Model\n",
    "y_predict = classifier_logistic.predict(X_train) # Predict results\n",
    "\n",
    "# Cross validation\n",
    "scores = model_selection.cross_val_score(classifier_logistic, X_train, y_train, cv = 10)\n",
    "print(f' For Logistic Regressional Classifier, the acc is {round(scores.mean()* 100, 2)} \\\n",
    "      ({round(scores.mean() * 100 - scores.std() * 100 * 1.96, 2)}\\\n",
    "      {round(scores.mean() * 100, 2) + round (scores.std() * 100 * 1.96, 2)} %')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = metrics.confusion_matrix(y_train, y_predict)\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show\n",
    "\n",
    "print(metrics.classification_report(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN Classifier\n",
    "classifier_KNN.fit(X_train, y_train) # Train Model\n",
    "y_predict = classifier_KNN.predict(X_train) # Predict results\n",
    "\n",
    "# Cross Validation\n",
    "scores = model_selection.cross_val_score(classifier_KNN, X_train, y_train, cv = 10)\n",
    "print(f' For KNN, the acc is {round(scores.mean() * 100, 2)}\\\n",
    "      ({round(scores.mean() * 100 - scores.std() * 100 * 1.96, 2)}\\\n",
    "      {round(scores.mean() * 100, 2) + round(scores.std() * 100 *1.96, 2)}) %')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = metrics.confusion_matrix(y_train, y_predict)\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "classifier_RF.fit(X_train, y_train) # Train Model\n",
    "y_predict = classifier_RF.predict(X_train) # Predict results\n",
    "\n",
    "# Cross validation\n",
    "scores = model_selection.cross_val_score(classifier_RF, X_train, y_train, cv = 10)\n",
    "print(f'For RF, the acc is {round(scores.mean() * 100, 2)}\\\n",
    "     ({round(scores.mean() * 100 - scores.std() * 100 * 1.96, 2)}\\\n",
    "      {round(scores.mean() * 100, 2) + round(scores.std() *100 * 1.96, 2)}) %')\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = metrics.confusion_matrix(y_train, y_predict)\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVC\n",
    "classifier_SVC.fit(X_train, y_train) # Train Model\n",
    "y_predict = classifier_SVC.predict(X_train) # Predict results\n",
    "\n",
    "# Cross validation\n",
    "scores = model_selection.cross_val_score(classifier_SVC, X_train, y_train, cv = 10)\n",
    "print(f'For SVC, the acc is {round(scores.mean() * 100, 2)}\\\n",
    "     ({round(scores.mean() * 100 - scores.std() * 100 * 1.96, 2)}\\\n",
    "      {round(scores.mean() * 100, 2) + round(scores.std() *100 * 1.96, 2)}) %')\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = metrics.confusion_matrix(y_train, y_predict)\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GB Classifier\n",
    "classifier_GB.fit(X_train, y_train) # Train Model\n",
    "y_predict = classifier_GB.predict(X_train) # Predict results\n",
    "\n",
    "# Cross validation\n",
    "scores = model_selection.cross_val_score(classifier_GB, X_train, y_train, cv = 10)\n",
    "print(f'For GB Classifier, the acc is {round(scores.mean() * 100, 2)}\\\n",
    "     ({round(scores.mean() * 100 - scores.std() * 100 * 1.96, 2)}\\\n",
    "      {round(scores.mean() * 100, 2) + round(scores.std() *100 * 1.96, 2)}) %')\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = metrics.confusion_matrix(y_train, y_predict)\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes\n",
    "classifier_NB.fit(X_train, y_train, sample_weight=None) # Train Model\n",
    "y_predict = classifier_NB.predict(X_train) # Predict results\n",
    "\n",
    "# Cross validation\n",
    "scores = model_selection.cross_val_score(classifier_NB, X_train, y_train, cv = 10)\n",
    "print(f'For Naive Bayes Classifier, the acc is {round(scores.mean() * 100, 2)}\\\n",
    "     ({round(scores.mean() * 100 - scores.std() * 100 * 1.96, 2)}\\\n",
    "      {round(scores.mean() * 100, 2) + round(scores.std() *100 * 1.96, 2)}) %')\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = metrics.confusion_matrix(y_train, y_predict)\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimize Hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# helper function for printing out grid search results \n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: \" + str(gs.best_score_))\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(param_name + ':' + str(best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - Logistic Regression\n",
    "parameters = {\n",
    "    'penalty':('l2','l1'),\n",
    "    'C': (0.036, 0.037, 0.038, 0.039, 0.040, 0.041, 0.042)\n",
    "    \n",
    "}\n",
    "Grid_LR = GridSearchCV(LogisticRegression(solver='liblinear'),parameters, cv = 10)\n",
    "Grid_LR.fit(X_train, y_train)\n",
    "# the best hyperparameter combination\n",
    "# C = 1/lambda\n",
    "print_grid_search_metrics(Grid_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_LR_model = Grid_LR.best_estimator_\n",
    "\n",
    "best_LR_model.predict(X_test)\n",
    "\n",
    "print('The test acc of the \"best\" model for LR is', best_LR_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 _ KNN Model\n",
    "\n",
    "# timing\n",
    "start = time.time()\n",
    "# Choose k and more\n",
    "parameters = {\n",
    " 'n_neighbors':[7,8,9,10,11,12,13,14,15],\n",
    " 'weights':['uniform', 'distance'],\n",
    " 'leaf_size':[1,2,3,4,5,6,7],\n",
    "}\n",
    "Grid_KNN = GridSearchCV(KNeighborsClassifier(),parameters, cv=10)\n",
    "Grid_KNN.fit(X_train, y_train)\n",
    "# the best hyperparameter combination\n",
    "print_grid_search_metrics(Grid_KNN) \n",
    "end = time.time()\n",
    "print(f'For KNN, it took {(end - start)/(9 * 2 * 7)} seconds per parameter attempt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_KNN_model = Grid_KNN.best_estimator_\n",
    "\n",
    "best_KNN_model.predict(X_test)\n",
    "\n",
    "print('The test acc of the \"best\" model for KNN is', best_KNN_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3 - RF\n",
    "# timing\n",
    "start = time.time()\n",
    "# Possible hyperparamter options for Random Forest\n",
    "# Choose the number of trees\n",
    "parameters = {\n",
    " 'n_estimators' : [65, 64, 63, 62, 61, 60],\n",
    " 'max_depth': [8,9,10,11]\n",
    "}\n",
    "Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=10)\n",
    "Grid_RF.fit(X_train, y_train)\n",
    "# the best hyperparameter combination\n",
    "print_grid_search_metrics(Grid_RF)\n",
    "end = time.time()\n",
    "print(f'For Random Forest, it took {(end - start)/(6 * 4)} seconds per parameter attempt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_RF_model = Grid_RF.best_estimator_\n",
    "best_RF_model.predict(X_test)\n",
    "print('The test acc of the \"best\" model for RF is', best_RF_model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 4 _ SVC\n",
    "\n",
    "# timing\n",
    "start = time.time()\n",
    "# Possible hyperparamter options for SVC\n",
    "parameters = {\n",
    " 'C' : [9, 10, 11, 12],\n",
    " 'degree': [0,1,2],\n",
    "}\n",
    "Grid_SVC = GridSearchCV(SVC(probability = True), parameters, cv=10)\n",
    "Grid_SVC.fit(X_train, y_train)\n",
    "# the best hyperparameter combination\n",
    "print_grid_search_metrics(Grid_SVC)\n",
    "\n",
    "end = time.time()\n",
    "print(f'For SVC, it took {(end - start)/(4 * 3)} seconds per parameter attempt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_SVC_model = Grid_SVC.best_estimator_\n",
    "best_SVC_model.predict(X_test)\n",
    "print('The test acc of the \"best\" model for SVC is', best_SVC_model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible hyperparamter options for GB Classifier\n",
    "parameters = {\n",
    " 'learning_rate' : [0.8, 0.9, 1.0],\n",
    " 'n_estimators': [63, 64, 65],\n",
    " 'subsample': [0.95, 1.0, 1.05],\n",
    " 'min_samples_split':[0.725, 0.75, 0.775]\n",
    "}\n",
    "Grid_GB = GridSearchCV(GradientBoostingClassifier(), parameters, cv=10)\n",
    "Grid_GB.fit(X_train, y_train)\n",
    "# the best hyperparameter combination\n",
    "print_grid_search_metrics(Grid_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_GB_model = Grid_GB.best_estimator_\n",
    "best_GB_model.predict(X_test)\n",
    "print('The test acc of the \"best\" model for GB classifier is', best_GB_model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6 - Gaussian Naive Bayes\n",
    "# Possible hyperparamter options for Gaussian Naive Bayes\n",
    "parameters = {\n",
    " 'var_smoothing' : [0.17, 0.18, 0.19],\n",
    "}\n",
    "Grid_NB = GridSearchCV(GaussianNB(), parameters, cv=10)\n",
    "Grid_NB.fit(X_train, y_train)\n",
    "# the best hyperparameter combination\n",
    "print_grid_search_metrics(Grid_NB) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_NB_model = Grid_NB.best_estimator_\n",
    "best_NB_model.predict(X_test)\n",
    "print('The test acc of the \"best\" model for Gaussian Naive Bayes classifier is', best_NB_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Evaluation - Confusion Matrix (Precision,Recall, Accuracy, f1-Score)\n",
    "\n",
    "#Precision(PPV, positive predictive value): tp / (tp + fp); High Precision means low fp\n",
    "#Recall(sensitivity, hit rate, true positive rate): tp / (tp + fn)\n",
    "#Accurracy: (tp + tn) / (tp + tn + fp + fn)\n",
    "#f1-Score: (2 * P * R) / (P + R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - Logistic Regression\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, best_LR_model.predict(X_test))\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, best_LR_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 - KNN Model\n",
    "cm = metrics.confusion_matrix(y_test, best_KNN_model.predict(X_test))\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, best_KNN_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 - RF\n",
    "cm = metrics.confusion_matrix(y_test, best_RF_model.predict(X_test))\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, best_RF_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 - SVC\n",
    "cm = metrics.confusion_matrix(y_test, best_SVC_model.predict(X_test))\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, best_SVC_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5 - GB Classifier\n",
    "cm = metrics.confusion_matrix(y_test, best_GB_model.predict(X_test))\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, best_GB_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6 - Gaussian Naive Bayes\n",
    "cm = metrics.confusion_matrix(y_test, best_NB_model.predict(X_test))\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, best_NB_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Evaluation - ROC & AUC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - Logistic Regression\n",
    "# Use predict_proba to get the probability results of LR\n",
    "y_pred_lr = best_LR_model.predict_proba(X_test)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_lr)\n",
    "# drawing ROC curve\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_lr, tpr_lr, label='LR')\n",
    "plt.xlabel('False positive rate')\n",
    "\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - LR model')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# AUC\n",
    "print('The AUC of LR model is', metrics.auc(fpr_lr,tpr_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2 - KNN\n",
    "# Use predict_proba to get the probability results of KNN\n",
    "y_pred_knn = best_KNN_model.predict_proba(X_test)[:, 1]\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_pred_knn)\n",
    "# drawing ROC curve\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - KNN model')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# AUC\n",
    "print('The AUC of KNN model is', metrics.auc(fpr_knn,tpr_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3 - Random Forest\n",
    "# Use predict_proba to get the probability results of Random Forest\n",
    "y_pred_rf = best_RF_model.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "# drawing ROC curve\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - RF model')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# AUC\n",
    "print('The AUC of RF model is', metrics.auc(fpr_rf,tpr_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 4 - SVC\n",
    "# Use predict_proba to get the probability results of SVC\n",
    "y_pred_svc = best_SVC_model.predict_proba(X_test)[:, 1]\n",
    "fpr_svc, tpr_svc, _ = roc_curve(y_test, y_pred_svc)\n",
    "# drawing ROC curve\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_svc, tpr_svc, label='SVC')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - SVC model')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# AUC\n",
    "print('The AUC of SVC model is', metrics.auc(fpr_svc,tpr_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 5 - GB Classifier\n",
    "# Use predict_proba to get the probability results of GB Classifier\n",
    "y_pred_gb = best_GB_model.predict_proba(X_test)[:, 1]\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y_test, y_pred_gb)\n",
    "# drawing ROC curve\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_gb, tpr_gb, label='GB')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - GB Classifier')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# AUC\n",
    "print('The AUC of GB Classifier is', metrics.auc(fpr_gb,tpr_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 6 - Gaussian Naive Bayes Classifier\n",
    "# Use predict_proba to get the probability results of Gaussian Naive Bayes Classification\n",
    "y_pred_gb = best_NB_model.predict_proba(X_test)[:, 1]\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y_test, y_pred_gb)\n",
    "# drawing ROC curve\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_gb, tpr_gb, label='NB')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - NB Classifier')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# AUC\n",
    "print('The AUC of NB Classifier is', metrics.auc(fpr_gb,tpr_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Insight\n",
    "#- RF, KNN, SVC excelled in predicting the occurrence of Heart failure through the given features in this dataset, with proper feature preprocessing. \n",
    "#-However, we need more data to verify the model prediction & train the model to avoid overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
